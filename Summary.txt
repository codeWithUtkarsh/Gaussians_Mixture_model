A widely used clustering technique is referred to as K-means, which employs an iterative process to update the parameters of each cluster. Specifically, it calculates the means (or centroids) of each cluster and then measures their distance from individual data points. Subsequently, data points are assigned to the cluster whose centroid is closest to them. This process iterates until a convergence criterion is reached, such as when no further changes in cluster assignments occur.

An important aspect of K-means is its classification as a hard clustering method, meaning it assigns each point exclusively to one cluster. However, a drawback of this approach is the absence of an uncertainty measure or probability indicating the degree of association between a data point and a specific cluster. To address this limitation, an alternative approach involves utilizing soft clustering methods instead of hard ones. Gaussian Mixture Models (GMMs), for instance, aim to achieve this by allowing for more flexible cluster assignments. Let's delve into a deeper exploration of this method.
